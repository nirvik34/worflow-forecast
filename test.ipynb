{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "49bad610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import lru_cache\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4b53da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET = pd.read_csv(\"data/dataset2.csv\")\n",
    "# DATASET['date'] = pd.to_datetime(DATASET['date'])\n",
    "# DATASET.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "93e61061",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = load_model('./model/model.keras', compile=False)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    scaler_X = joblib.load('./model/scaler_X.pkl')\n",
    "    scaler_y = joblib.load('./model/scaler_y.pkl')\n",
    "    encoder = joblib.load('./model/encoder.pkl')\n",
    "except FileNotFoundError as e:\n",
    "    sys.exit(f\"[FATAL] Missing file: {e.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "828892a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_date(target_date_str):\n",
    "    try:\n",
    "        target_date = pd.Timestamp(target_date_str)\n",
    "    except:\n",
    "        raise ValueError(\"Invalid date format. Use YYYY-MM-DD\")\n",
    "    if target_date.date() < datetime.today().date():\n",
    "        raise ValueError(\"Past dates are not allowed. Select a future date.\")\n",
    "    return target_date\n",
    "\n",
    "def safe_numeric(value, default=0.0):\n",
    "    if pd.isna(value) or np.isinf(value):\n",
    "        return default\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a5db17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_forecast(lat, lon, target_date):\n",
    "    \"\"\"\n",
    "    Fetch weather forecast for given lat/lon and date from Open-Meteo.\n",
    "    Returns a dict with rainfall, temperatures, weather_score.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://api.open-meteo.com/v1/forecast\"\n",
    "        f\"?latitude={lat}&longitude={lon}\"\n",
    "        f\"&daily=precipitation_sum,temperature_2m_max,temperature_2m_min\"\n",
    "        f\"&start_date={target_date}&end_date={target_date}\"\n",
    "        f\"&timezone=UTC\"\n",
    "    )\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        daily = data.get('daily', {})\n",
    "        rainfall = float(daily.get('precipitation_sum', [0])[0])\n",
    "        temp_max = float(daily.get('temperature_2m_max', [0])[0])\n",
    "        temp_min = float(daily.get('temperature_2m_min', [0])[0])\n",
    "        # Simple weather score: high rainfall increases severity\n",
    "        if rainfall > 20:\n",
    "            weather_score = 1.5\n",
    "        elif rainfall > 5:\n",
    "            weather_score = 1.2\n",
    "        else:\n",
    "            weather_score = 1.0\n",
    "        return {\n",
    "            \"rainfall_mm\": rainfall,\n",
    "            \"temp_max\": temp_max,\n",
    "            \"temp_min\": temp_min,\n",
    "            \"weather_score\": weather_score\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"rainfall_mm\": 0.0, \"temp_max\": None, \"temp_min\": None, \"weather_score\": 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "93d52a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_workforce(predicted_cases, problem_type, region=None, severity_score=None, df=None,\n",
    "                                urgency_factor=1.0, max_workers=200, weather=None, return_explanation=False):\n",
    "    \"\"\"\n",
    "    Calculate workforce dynamically with realistic scaling + weather adjustment.\n",
    "    \"\"\"\n",
    "    explanation = []\n",
    "\n",
    "    # Default dynamic values if df is missing\n",
    "    if df is None or df.empty:\n",
    "        avg_cases_per_worker = np.random.uniform(0.8, 1.5)\n",
    "        base_staff = np.random.randint(1, 5)\n",
    "        efficiency_factor = np.random.uniform(0.7, 0.95)\n",
    "        severity_score = severity_score or np.random.randint(1, 5)\n",
    "    else:\n",
    "        subset = df[df['problem_type'].str.strip().str.title() == problem_type.title()]\n",
    "        if subset.empty:\n",
    "            avg_cases_per_worker = np.random.uniform(0.8, 1.5)\n",
    "            base_staff = np.random.randint(1, 5)\n",
    "            efficiency_factor = np.random.uniform(0.7, 0.95)\n",
    "            severity_score = severity_score or np.random.randint(1, 5)\n",
    "        else:\n",
    "            avg_cases_per_worker = max(0.5, subset['reported_cases'].mean() / max(1, subset['workforce_required'].mean()))\n",
    "            base_staff = max(1, int(subset['workforce_required'].min() * 0.5))\n",
    "            efficiency_factor = min(1.0, 0.75 + (subset['severity_score'].mean() - 2) * 0.05)\n",
    "            severity_score = severity_score or int(subset['severity_score'].iloc[-1])\n",
    "\n",
    "    # Weather adjustment\n",
    "    weather_factor = 1.0\n",
    "    if weather:\n",
    "        weather_factor = weather.get(\"weather_score\", 1.0)\n",
    "        # Increase severity if heavy rain, slightly reduce efficiency\n",
    "        severity_score = int(round(severity_score * weather_factor))\n",
    "        efficiency_factor *= 0.95 if weather.get(\"rainfall_mm\", 0) > 5 else 1.0\n",
    "\n",
    "    # Non-linear severity multiplier\n",
    "    severity_multiplier = 1 + (severity_score ** 1.5) * 0.25\n",
    "\n",
    "    # Effective cases adjusted by efficiency\n",
    "    effective_cases = predicted_cases / efficiency_factor\n",
    "\n",
    "    # Dynamic cases per worker\n",
    "    problem_complexity = {\n",
    "        \"Garbage & Waste\": 1.0,\n",
    "        \"Water Supply\": 1.2,\n",
    "        \"Road Maintenance\": 0.9,\n",
    "        \"Electricity\": 1.3,\n",
    "        \"Public Safety\": 1.5,\n",
    "        \"Drainage\": 1.1,\n",
    "        \"Mosquito Control\": 1.4,\n",
    "        \"Pothole\": 1.3,\n",
    "    }\n",
    "    complexity_factor = problem_complexity.get(problem_type.title(), 1.0)\n",
    "    workforce = (effective_cases / (avg_cases_per_worker * complexity_factor)) * severity_multiplier\n",
    "\n",
    "    workforce += base_staff\n",
    "    workforce *= urgency_factor\n",
    "\n",
    "    capped = False\n",
    "    if workforce > max_workers:\n",
    "        workforce = max_workers\n",
    "        capped = True\n",
    "\n",
    "    if return_explanation:\n",
    "        explanation.append(f\"Predicted cases: {predicted_cases}\")\n",
    "        explanation.append(f\"Severity score (weather-adjusted): {severity_score}, multiplier: {severity_multiplier:.2f}\")\n",
    "        explanation.append(f\"Efficiency factor: {efficiency_factor:.2f}, effective cases: {effective_cases:.1f}\")\n",
    "        if weather:\n",
    "            explanation.append(f\"Weather: Rainfall {weather['rainfall_mm']}mm, TempMax {weather['temp_max']}Â°C\")\n",
    "        explanation.append(f\"Avg cases per worker: {avg_cases_per_worker:.2f}, problem complexity factor: {complexity_factor}\")\n",
    "        explanation.append(f\"Base staff: {base_staff}\")\n",
    "        if urgency_factor != 1.0:\n",
    "            explanation.append(f\"Urgency factor applied: {urgency_factor}\")\n",
    "        if capped:\n",
    "            explanation.append(f\"Workforce capped to max allowed: {max_workers}\")\n",
    "        explanation.append(f\"Final workforce allocated: {int(round(workforce))}\")\n",
    "        return max(1, int(round(workforce))), \" \".join(explanation)\n",
    "\n",
    "    return max(1, int(round(workforce)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7636521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_case_range(df, problem_type):\n",
    "    subset = df[df['problem_type'].str.strip().str.title() == problem_type.title()]\n",
    "    if subset.empty:\n",
    "        return 1, 20\n",
    "    min_cases = int(subset['reported_cases'].min())\n",
    "    max_cases = int(subset['reported_cases'].max())\n",
    "    if min_cases == max_cases:\n",
    "        max_cases = min_cases + 5\n",
    "    return min_cases, max_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3f067547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(problem_type, df=None, weather=None):\n",
    "    min_cases, max_cases = 1, 20\n",
    "    if df is not None and not df.empty:\n",
    "        min_cases, max_cases = get_dynamic_case_range(df, problem_type)\n",
    "    predicted_cases = np.random.randint(min_cases, max_cases + 1)\n",
    "    predicted_workforce, explanation = calculate_dynamic_workforce(predicted_cases, problem_type, df=df, weather=weather, return_explanation=True)\n",
    "    return predicted_cases, predicted_workforce, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0014f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(problem_type_input, target_date_str, lat=28.6139, lon=77.2090):\n",
    "    target_date = validate_date(target_date_str)\n",
    "    weather = get_weather_forecast(lat, lon, target_date.date())\n",
    "    try:\n",
    "        df = pd.read_csv(\"data/dataset2.csv\")\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.ffill(inplace=True)\n",
    "\n",
    "        subset = df[df['problem_type'].str.strip().str.title() == problem_type_input.title()].sort_values('date')\n",
    "        if subset.empty:\n",
    "            raise ValueError(f\"No historical data for {problem_type_input}\")\n",
    "\n",
    "        seq_len = 30\n",
    "        seq = subset.tail(seq_len).copy()\n",
    "        if len(seq) < seq_len:\n",
    "            last_row = seq.iloc[-1].copy()\n",
    "            last_date = last_row['date']\n",
    "            for i in range(seq_len - len(seq)):\n",
    "                new_row = last_row.copy()\n",
    "                new_row['date'] = last_date + pd.Timedelta(days=i+1)\n",
    "                seq = pd.concat([seq, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        X_seq_to_predict = seq.drop(columns=['date','reported_cases','workforce_required'], errors='ignore')\n",
    "\n",
    "        if 'problem_type' in X_seq_to_predict.columns and 'region' in X_seq_to_predict.columns:\n",
    "            cat_transformed = pd.DataFrame(encoder.transform(X_seq_to_predict[['problem_type','region']]),\n",
    "                                           columns=encoder.get_feature_names_out(['problem_type','region']))\n",
    "            X_seq_to_predict = pd.concat([X_seq_to_predict.drop(columns=['problem_type','region']), cat_transformed], axis=1)\n",
    "\n",
    "        X_scaled = scaler_X.transform(X_seq_to_predict)\n",
    "        X_input = np.array([X_scaled])\n",
    "        y_pred_scaled = model.predict(X_input, verbose=0)\n",
    "        predicted_cases = safe_numeric(int(round(scaler_y.inverse_transform(y_pred_scaled)[0,0])), 1)\n",
    "\n",
    "        predicted_workforce, explanation = calculate_dynamic_workforce(predicted_cases, problem_type_input, df=df, weather=weather, return_explanation=True)\n",
    "\n",
    "        return predicted_cases, predicted_workforce, explanation\n",
    "\n",
    "    except Exception:\n",
    "        return predict_random(problem_type_input, weather=weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "13a9f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Cannot compare NaT with datetime.date object\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    problem_type = input(\"Enter problem type: \").strip().title()\n",
    "    target_date = input(\"Enter target date (YYYY-MM-DD, future only): \").strip()\n",
    "    try:\n",
    "        cases, workforce, explanation = predict(problem_type, target_date)\n",
    "        print(\"\\n=== Prediction Result ===\")\n",
    "        print(f\"Date: {target_date}\")\n",
    "        print(f\"Problem Type: {problem_type}\")\n",
    "        print(f\"Predicted Reported Cases: {cases}\")\n",
    "        print(f\"Predicted Workforce Required: {workforce}\")\n",
    "        print(f\"\\nExplanation: {explanation}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e16db5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c166997",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f1df7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
