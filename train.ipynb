{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/dataset2.csv\")\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.fillna(method='ffill', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['day_of_week_sin'] = np.sin(2 * np.pi * df['date'].dt.weekday / 7)\n",
        "df['day_of_week_cos'] = np.cos(2 * np.pi * df['date'].dt.weekday / 7)\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)\n",
        "\n",
        "df['is_weekend'] = (df['date'].dt.weekday >= 5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['prev_day_cases'] = df.groupby('problem_type')['reported_cases'].shift(1).fillna(0)\n",
        "df['prev_3day_avg_cases'] = df.groupby('problem_type')['reported_cases'].rolling(3, min_periods=1).mean().reset_index(0, drop=True)\n",
        "df['problem_severity_interaction'] = df['severity_score'] * df['prev_day_cases']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_cols = ['problem_type','region']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "cat_encoded = encoder.fit_transform(df[categorical_cols])\n",
        "cat_encoded_df = pd.DataFrame(cat_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "df = pd.concat([df.reset_index(drop=True), cat_encoded_df], axis=1)\n",
        "df.drop(columns=categorical_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_features = [\n",
        "    'severity_score','is_weekend','holiday_flag',\n",
        "    'prev_day_cases','prev_3day_avg_cases','weather_score',\n",
        "    'rainfall_mm','problem_severity_interaction',\n",
        "    'day_of_week_sin','day_of_week_cos','month_sin','month_cos'\n",
        "]\n",
        "\n",
        "features = numerical_features + list(cat_encoded_df.columns)\n",
        "target = 'reported_cases'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(df[features])\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(df[[target]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequence_length = 30\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(sequence_length, len(X_scaled)):\n",
        "    X_seq.append(X_scaled[i-sequence_length:i])\n",
        "    y_seq.append(y_scaled[i])\n",
        "\n",
        "X_seq, y_seq = np.array(X_seq), np.array(y_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_idx = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
        "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('./model/model.keras')\n",
        "joblib.dump(scaler_X, './model/scaler_X.pkl')\n",
        "joblib.dump(scaler_y, './model/scaler_y.pkl')\n",
        "joblib.dump(encoder, './model/encoder.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
