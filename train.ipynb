{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nirvi\\AppData\\Local\\Temp\\ipykernel_3152\\4193721034.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df.fillna(method='ffill', inplace=True)\n",
            "d:\\Projects\\HACKATHONS\\SIH\\forecast2\\myvenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 194ms/step - loss: 0.0227 - val_loss: 0.0169\n",
            "Epoch 2/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 186ms/step - loss: 0.0215 - val_loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 189ms/step - loss: 0.0213 - val_loss: 0.0206\n",
            "Epoch 4/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 155ms/step - loss: 0.0211 - val_loss: 0.0194\n",
            "Epoch 5/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 188ms/step - loss: 0.0211 - val_loss: 0.0169\n",
            "Epoch 6/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 166ms/step - loss: 0.0210 - val_loss: 0.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 145ms/step - loss: 0.0210 - val_loss: 0.0156\n",
            "Epoch 8/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 194ms/step - loss: 0.0209 - val_loss: 0.0147\n",
            "Epoch 9/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 175ms/step - loss: 0.0209 - val_loss: 0.0162\n",
            "Epoch 10/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 151ms/step - loss: 0.0209 - val_loss: 0.0148\n",
            "Epoch 11/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 135ms/step - loss: 0.0209 - val_loss: 0.0143\n",
            "Epoch 12/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 125ms/step - loss: 0.0209 - val_loss: 0.0151\n",
            "Epoch 13/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 125ms/step - loss: 0.0209 - val_loss: 0.0148\n",
            "Epoch 14/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 125ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 15/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - loss: 0.0209 - val_loss: 0.0145\n",
            "Epoch 16/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 145ms/step - loss: 0.0209 - val_loss: 0.0150\n",
            "Epoch 17/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 135ms/step - loss: 0.0208 - val_loss: 0.0147\n",
            "Epoch 18/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 152ms/step - loss: 0.0209 - val_loss: 0.0158\n",
            "Epoch 19/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 120ms/step - loss: 0.0208 - val_loss: 0.0139\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['./model/encoder.pkl']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "\n",
        "# %% Load dataset\n",
        "df = pd.read_csv(\"data/dataset2.csv\")\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# %% Cyclical features for LSTM\n",
        "df['day_of_week_sin'] = np.sin(2 * np.pi * df['date'].dt.weekday / 7)\n",
        "df['day_of_week_cos'] = np.cos(2 * np.pi * df['date'].dt.weekday / 7)\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)\n",
        "\n",
        "df['is_weekend'] = (df['date'].dt.weekday >= 5).astype(int)\n",
        "\n",
        "# %% Lag features\n",
        "df['prev_day_cases'] = df.groupby('problem_type')['reported_cases'].shift(1).fillna(0)\n",
        "df['prev_3day_avg_cases'] = df.groupby('problem_type')['reported_cases'].rolling(3, min_periods=1).mean().reset_index(0, drop=True)\n",
        "df['problem_severity_interaction'] = df['severity_score'] * df['prev_day_cases']\n",
        "\n",
        "# %% Encode categorical\n",
        "categorical_cols = ['problem_type','region']\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "cat_encoded = encoder.fit_transform(df[categorical_cols])\n",
        "cat_encoded_df = pd.DataFrame(cat_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "df = pd.concat([df.reset_index(drop=True), cat_encoded_df], axis=1)\n",
        "df.drop(columns=categorical_cols, inplace=True)\n",
        "\n",
        "# %% Features & Target\n",
        "numerical_features = [\n",
        "    'severity_score','is_weekend','holiday_flag',\n",
        "    'prev_day_cases','prev_3day_avg_cases','weather_score',\n",
        "    'rainfall_mm','problem_severity_interaction',\n",
        "    'day_of_week_sin','day_of_week_cos','month_sin','month_cos'\n",
        "]\n",
        "\n",
        "features = numerical_features + list(cat_encoded_df.columns)\n",
        "target = 'reported_cases'\n",
        "\n",
        "# %% Scale data using MinMaxScaler\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(df[features])\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(df[[target]])\n",
        "\n",
        "# %% Create sequences for LSTM\n",
        "sequence_length = 30\n",
        "X_seq, y_seq = [], []\n",
        "for i in range(sequence_length, len(X_scaled)):\n",
        "    X_seq.append(X_scaled[i-sequence_length:i])\n",
        "    y_seq.append(y_scaled[i])\n",
        "\n",
        "X_seq, y_seq = np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# %% Train-test split\n",
        "split_idx = int(0.8 * len(X_seq))\n",
        "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
        "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]\n",
        "\n",
        "# %% Build LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# %% Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# %% Save model & scalers & encoder\n",
        "model.save('./model/model.keras')\n",
        "joblib.dump(scaler_X, './model/scaler_X.pkl')\n",
        "joblib.dump(scaler_y, './model/scaler_y.pkl')\n",
        "joblib.dump(encoder, './model/encoder.pkl')\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
